{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USE TRAIN] Load use embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/07 16:13:57 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2023/07/07 16:13:57 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USE TRAIN] done\n",
      "Name: NLP_TOPIC_MODELLING \n",
      "Experiment_id: 214077180342566652\n",
      "Artifact Location: file:///c:/dev/topic_modelling/API/mlruns\n",
      "Tags: {'priority': 'P1', 'version': 'v1'}\n",
      "Lifecycle_stage: active\n",
      "Creation timestamp: 1688739237654\n",
      "[USE TRAIN] Active run_id: 300b67aef51f42f89c19bb7462897d98\n",
      "[USE TRAIN] Current tracking uri: file://C:\\dev\\topic_modelling\\output\\logs\\mlruns\n",
      "[USE TRAIN] Load data ...\n",
      "386\n",
      "96\n",
      "[USE TRAIN] Load completed\n",
      "[USE TRAIN] Generate the embedding of the data ...\n",
      "[USE TRAIN] embedding completed\n",
      "[USE TRAIN] Get model and fit ...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                3870      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,094\n",
      "Trainable params: 168,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/07 16:14:11 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: If 'features' is a TensorFlow Tensor, then 'targets' must also be a TensorFlow Tensor. Found: <class 'numpy.ndarray'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.0596\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.1658\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5980 - accuracy: 0.1891\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.1891\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.1891\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2863 - accuracy: 0.1891\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2230 - accuracy: 0.1891\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2096 - accuracy: 0.1891\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.1891\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.1891\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2049 - accuracy: 0.1891\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.1891\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.1995\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.3031\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.3057\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.2979\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1858 - accuracy: 0.3679\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.3601\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.3679\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.3756\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.3886\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.4378\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.4223\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.4119\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1700 - accuracy: 0.3731\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.3212\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.2979\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.3161\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.3394\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.4223\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.4767\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1526 - accuracy: 0.5026\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.5259\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.5596\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.5622\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.5596\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.5674\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1384 - accuracy: 0.5933\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.6088\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1338 - accuracy: 0.6140\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.6192\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.6192\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1290 - accuracy: 0.6192\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.6295\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.6606\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.6658\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.6554\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.6399\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1195 - accuracy: 0.6373\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.6606\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.6917\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.7021\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.6943\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1111 - accuracy: 0.6969\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.7124\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.7150\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.7150\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.7176\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1041 - accuracy: 0.7332\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.7254\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1018 - accuracy: 0.7021\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.6813\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0998 - accuracy: 0.6839\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.6865\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.7124\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.7487\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.7617\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.7565\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.7435\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.7254\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.7254\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0900 - accuracy: 0.7332\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.7565\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.7513\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.7383\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.7513\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.7565\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.7668\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.7694\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0814 - accuracy: 0.7642\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.7798\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.7617\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.7591\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.7487\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.7617\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.7772\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0761 - accuracy: 0.7798\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.7850\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.7876\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.7979\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.7953\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.8057\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.8161\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.8187\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 0.8135\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.8031\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.7979\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.7953\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpg5slc6zi\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpg5slc6zi\\model\\data\\model\\assets\n",
      "2023/07/07 16:14:25 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpg5slc6zi\\model, flavor: tensorflow), fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "[USE TRAIN] Decision threshold :  0.25118864315094075\n",
      "[USE TRAIN] Saving best threshold .... \n",
      "[USE TRAIN] Model trained\n",
      "[USE TRAIN] Evaluation .... \n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[USE TRAIN] done\n",
      "[USE TRAIN] Save model .... \n",
      "[USE TRAIN] done\n"
     ]
    }
   ],
   "source": [
    "%run \"C:\\dev\\\\topic_modelling\\API\\\\train.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                                             Name                 ID                              \n",
      "-----------------------------------------------  -------------------  --------------------------------\n",
      "2023-07-07 13:08:17 Paris, Madrid (heure d’été)  casual-bat-801       fc08d99e82c942828f39750ae6423ecb\n",
      "2023-07-07 12:27:57 Paris, Madrid (heure d’été)  clean-crab-12        9751e91625924a1eb45a1e44c56e9499\n",
      "2023-07-07 12:26:25 Paris, Madrid (heure d’été)  unleashed-robin-719  ec59a73766cd4675b27b020c159db611\n",
      "2023-07-07 12:23:35 Paris, Madrid (heure d’été)  welcoming-cod-544    b3bfe6853a154967a86a4be122983438\n"
     ]
    }
   ],
   "source": [
    "!mlflow runs list --experiment-id 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'USE_TOPIC_CLASSIFIER'.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Run '1' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUSE_TOPIC_CLASSIFIER\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m run_uri \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mruns:/\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m model_version \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39;49mregister_model(run_uri,model_name)\n",
      "File \u001b[1;32mc:\\dev\\topic_modelling\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:90\u001b[0m, in \u001b[0;36mregister_model\u001b[1;34m(model_uri, name, await_registration_for, tags)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m RunsArtifactRepository\u001b[39m.\u001b[39mis_runs_uri(model_uri):\n\u001b[1;32m---> 90\u001b[0m     source \u001b[39m=\u001b[39m RunsArtifactRepository\u001b[39m.\u001b[39;49mget_underlying_uri(model_uri)\n\u001b[0;32m     91\u001b[0m     (run_id, _) \u001b[39m=\u001b[39m RunsArtifactRepository\u001b[39m.\u001b[39mparse_runs_uri(model_uri)\n\u001b[0;32m     92\u001b[0m     create_version_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mcreate_model_version(\n\u001b[0;32m     93\u001b[0m         name, source, run_id, tags\u001b[39m=\u001b[39mtags, await_creation_for\u001b[39m=\u001b[39mawait_registration_for\n\u001b[0;32m     94\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\topic_modelling\\lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:39\u001b[0m, in \u001b[0;36mRunsArtifactRepository.get_underlying_uri\u001b[1;34m(runs_uri)\u001b[0m\n\u001b[0;32m     37\u001b[0m (run_id, artifact_path) \u001b[39m=\u001b[39m RunsArtifactRepository\u001b[39m.\u001b[39mparse_runs_uri(runs_uri)\n\u001b[0;32m     38\u001b[0m tracking_uri \u001b[39m=\u001b[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001b[1;32m---> 39\u001b[0m uri \u001b[39m=\u001b[39m get_artifact_uri(run_id, artifact_path, tracking_uri)\n\u001b[0;32m     40\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m RunsArtifactRepository\u001b[39m.\u001b[39mis_runs_uri(uri)  \u001b[39m# avoid an infinite loop\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(uri, tracking_uri)\n",
      "File \u001b[1;32mc:\\dev\\topic_modelling\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:47\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[1;34m(run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     42\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA run_id must be specified in order to obtain an artifact uri!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m         error_code\u001b[39m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     46\u001b[0m store \u001b[39m=\u001b[39m _get_store(tracking_uri)\n\u001b[1;32m---> 47\u001b[0m run \u001b[39m=\u001b[39m store\u001b[39m.\u001b[39;49mget_run(run_id)\n\u001b[0;32m     48\u001b[0m \u001b[39m# Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39massert\u001b[39;00m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39murlparse(run\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39martifact_uri)\u001b[39m.\u001b[39mscheme \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mruns\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# avoid an infinite loop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\topic_modelling\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:656\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[1;34m(self, run_id)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \u001b[39mNote: Will get both active and deleted runs.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    655\u001b[0m _validate_run_id(run_id)\n\u001b[1;32m--> 656\u001b[0m run_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_run_info(run_id)\n\u001b[0;32m    657\u001b[0m \u001b[39mif\u001b[39;00m run_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    659\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRun \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m metadata is in invalid state.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m run_id, databricks_pb2\u001b[39m.\u001b[39mINVALID_STATE\n\u001b[0;32m    660\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\topic_modelling\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:680\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[1;34m(self, run_uuid)\u001b[0m\n\u001b[0;32m    678\u001b[0m exp_id, run_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_run_root(run_uuid)\n\u001b[0;32m    679\u001b[0m \u001b[39mif\u001b[39;00m run_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRun \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m run_uuid, databricks_pb2\u001b[39m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[0;32m    682\u001b[0m     )\n\u001b[0;32m    683\u001b[0m run_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_run_info_from_dir(run_dir)\n\u001b[0;32m    684\u001b[0m \u001b[39mif\u001b[39;00m run_info\u001b[39m.\u001b[39mexperiment_id \u001b[39m!=\u001b[39m exp_id:\n",
      "\u001b[1;31mMlflowException\u001b[0m: Run '1' not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "run_id = 1 \n",
    "model_name = \"USE_TOPIC_CLASSIFIER\"\n",
    "\n",
    "run_uri = f'runs:/{run_id}/'\n",
    "\n",
    "model_version = mlflow.register_model(run_uri,model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
